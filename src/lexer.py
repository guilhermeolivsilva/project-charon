"""Implement a lexer for the Tiny C compiler."""


class Lexer:
    types = {
        "int": "INT_TYPE",
        "float": "FLOAT_TYPE",
        "long": "LONG_TYPE"
    }

    conditionals = {
        "do": "DO_SYM",
        "while": "WHILE_SYM",
        "if": "IF_SYM",
        "else": "ELSE_SYM"
    }

    symbols = {
        "{": "LCBRA",
        "}": "RCBRA",
        "[": "LBRA",
        "]": "RBRA",
        "(": "LPAR",
        ")": "RPAR",
        "+": "PLUS",
        "-": "MINUS",
        "<": "LESS",
        ";": "SEMI",
        "=": "EQUAL",
        ".": "DOT"
    }

    reserved_words = {
        **types,
        **conditionals,
        **symbols,

        # Additional reserved words that are not in previous categories
        "struct": "STRUCT_DEF",
        "return": "RET_SYM"
    }

    def __init__(self, source_code: str) -> None:
        self.source_code: str = source_code
        self.functions: dict[str, dict[str, str]] = {}
        self.variables: dict[str, str] = {}
        self.structs: dict[str, dict[str, str]] = {}

    def parse_source_code(self) -> dict:
        """
        Parse the source code and generate tokens from it.

        Returns
        -------
        parsed_source_code : dict of lists
            A dictionary with lists of tokens that represent the source code.
            Each list encompass a scope (globals, main, and user defined
            functions). All lists have been validated, and are syntactically
            correct.
        """

        symbol_collection = self.split_source()

        tokenized_source_code = list(
            map(
                self.parse_word,
                self.split_source()
            )
        )

        postprocessed_source_code = self.postprocess_source_code(
            tokenized_source_code=tokenized_source_code
        )

        self.validate_source_code_syntax(postprocessed_source_code)

        return postprocessed_source_code

    def split_source(self) -> list[str]:
        """
        Split the source code in individual words and symbols.

        This method is intended to handle reserved words, spaces, line breaks
        and other style-related issues.

        Returns
        -------
        tokenized_source_code : list of str
            A list of words and individual characters obtained from the source
            code.
        """

        # Remove line breaks
        source_code = self.source_code.replace("\n", "")

        # Collapse `long int` to just `long`
        source_code = source_code.replace("long int", "long")

        # Replace commas with spaces
        source_code = source_code.replace(",", " ")

        # Tweak braces, parenthesis and semicolons before splitting the string
        # by blank spaces
        tokens_to_tweak = ["(", ")", "{", "}", ";", "[", "]"]
        for token in tokens_to_tweak:
            source_code = source_code.replace(token, f" {token} ")

        # Split the code word by word (or character by character)
        source_code = source_code.split(" ")

        # Remove empty tokens
        tokenized_source = list(
            filter(lambda curr_token: curr_token if len(curr_token) > 0 else None, source_code)
        )

        return tokenized_source
    
    def annotate_source(self, symbol_collection: list[str]) -> list[str]:
        """
        Annotate the variables, constants and functions of the source.

        Parameters
        ----------
        symbol_collection : list of str
            The collection of symbols generated by the `split_source` method.

        Returns
        -------
        annotated_source : list of str
            The `symbol_collection`, but with preffixes that identify
            variable and function declarations/usage, and constants.
        """

        ...

    def _annotate_constants(self, symbol_collection: list[str]) -> list[str]:
        """
        Annotate constants with types.

        Parameters
        ----------
        symbol_collection : list of str
            The collection of symbols generated by the `split_source` method.

        Returns
        -------
        symbol_collection : list of str
            The `symbol_collection` with annotated constants.
        """

        for idx, token in enumerate(symbol_collection):
            try:
                _ = int(token)
                symbol_collection[idx] = "int_cst_" + token
                continue

            except ValueError:
                pass

            try:
                _ = float(token)
                symbol_collection[idx] = "float_cst_" + token
                continue

            except ValueError:
                pass

        return symbol_collection
    
    def _annotate_functions(self, symbol_collection: list[str]) -> list[str]:
        """
        Annotate functions with the preffixes for definitions and calls.

        Parameters
        ----------
        symbol_collection : list of str
            The collection of symbols generated by the `split_source` method.

        Returns
        -------
        symbol_collection : list of str
            The `symbol_collection` with annotated variables.

        Raises
        ------
        SyntaxError
        """

        declared_main = False

        for idx, token in enumerate(symbol_collection):
            # Skip `word` if it is a known symbol/reserved word or an annotated
            # constant, skip it
            already_handled = (
                (token in self.reserved_words)
                or ("cst" in token)
            )
            if already_handled:
                continue

            succeeded_by_left_parenthesis = symbol_collection[idx + 1] == "("

            # We assume that all functions references (either definition or
            # callings) are `<func_name> <(> ...`. Then, if the next symbol is
            # not a left parenthesis (`(`), it must not be a function.
            if not succeeded_by_left_parenthesis:
                continue

            # If followed by left parenthesis, decide whether it is a function
            # definition (not in `self.functions`, and preceeded by a type),
            # call (in `self.functions`, and not preceeded by a type), or a
            # syntax error (in `self.functions`, and preceeded by a type).
            preceeded_by_type = symbol_collection[idx - 1] in self.types
            function_is_known = token in self.functions

            # It is a definition
            if preceeded_by_type and not function_is_known:
                function_type = symbol_collection[idx - 1]
                preffix = "func_def_"

                # Save the indices of the first and last instruction of the
                # function for scope handling
                start_idx, end_idx = _get_function_limits(
                    symbol_collection=symbol_collection,
                    function_idx=idx
                )
                parameters = _extract_parameters(
                    symbol_collection=symbol_collection,
                    function_idx=idx
                )

                self.functions[token] = {
                    "type": function_type,
                    "start_idx": start_idx,
                    "end_idx": end_idx,
                    "parameters": parameters
                }

                # Set the `declared_main` flag
                declared_main = token == "main"

            # It is a call
            elif not preceeded_by_type and function_is_known:
                preffix = "func_call_"

            # It is a redefinition
            elif preceeded_by_type and function_is_known:
                err_msg = f"Redefinition of function '{token}'"
                raise SyntaxError(err_msg)
            
            symbol_collection[idx] = preffix + token
            continue

        if not declared_main:
            err_msg = "'main' function has not been declared."
            raise SyntaxError(err_msg)

        return symbol_collection
    
    def _annotate_variables(self, symbol_collection: list[str]) -> list[str]:
        """
        Annotate variables with the `var_` preffix.

        Also, check if the variables are valid (not named after a function, no
        variable is used before being declared, etc.).

        Parameters
        ----------
        symbol_collection : list of str
            The collection of symbols generated by the `split_source` method.

        Returns
        -------
        symbol_collection : list of str
            The `symbol_collection` with annotated variables.

        Raises
        ------
        SyntaxError
            Raised if the variable is
             - named after a function.
             - used before being declared.
             - incorrectly declared (eg., missing `;` or another valid symbol
               right after it). 
        """

        for idx, token in enumerate(symbol_collection):
            # Skip `word` if it is a known symbol/reserved word or an annotated
            # constant/function, skip it
            already_handled = (
                (token in self.reserved_words)
                or ("cst" in token)
                or ("func" in token)
            )
            if already_handled:
                continue

            # Check if it is a known variable
            if token in self.variables:
                symbol_collection[idx] = "var_" + token
                continue

            # Check if the variable is named after a function
            if token in self.functions:
                err_msg = f"Variable '{token} 'named after a function."
                raise SyntaxError(err_msg)

            # If not, check if it has a valid definition and add it to the list
            # of known variables: has a type and is followed by `=`, `;`, or ")".
            preceeded_by_type = symbol_collection[idx - 1] in self.types
            succeeded_by_valid_symbol = symbol_collection[idx + 1] in [";", "=", ")"]

            if preceeded_by_type:
                if not succeeded_by_valid_symbol:
                    err_msg = f"Invalid declaration of variable '{token}'."
                    raise SyntaxError(err_msg)
                
                self.variables[token] = symbol_collection[idx - 1]
                symbol_collection[idx] = "var_" + token

            else:
                err_msg = f"Usage of undeclared variable '{token}'."
                raise SyntaxError(err_msg)

        return symbol_collection

    def parse_word(self, word: str) -> tuple[str, int]:
        """
        Parse a word and return its corresponding symbol.

        Parameters
        ----------
        word : str
            The word to parse.

        Returns
        -------
        symbol : str
            The corresponding symbol to the given word.
        value : int or None
            The associated value, if any.

        Raises
        ------
        SyntaxError
            Raised if the input does not correspond to a supported symbol.
        """

        value = None

        # Try parsing the word as a known symbol or reserved word. If the
        # attempt fails, then pattern match the function/variable
        if word in self.reserved_words.keys():
            symbol = self.reserved_words[word]

        elif "func_" in word:
            symbol = "FUNC"
            value = word[5:]

        elif "var_" in word:
            symbol = "ID"
            value = word[4:]

        elif "float_" in word:
            symbol = "FLOAT"
            value = float(word[6:])

        elif "int_" in word:
            symbol = "INT"
            value = int(word[4:])

        elif "struct_" in word:
            symbol = "STRUCT"
            value = word[7:]

        else:
            raise SyntaxError(f"Syntax error at '{word}'.")

        return (symbol, value)

    def postprocess_source_code(self, tokenized_source_code: list) -> list:
        """
        Post-process the source code to handle user defined types (structs).

        Parameters
        ----------
        tokenized_source_code : list of (str, str | int | float | None) tuples
            The list of tokens generated from mapping all the words to the
            `parse_word` method.

        Returns
        -------
        postprocessed_source_code : list of (str, str | int | float | None) tuples
            The post-processed source code.

        Raises
        ------
        TODO
        """

        postprocessed_source_code = tokenized_source_code

        for idx, token in enumerate(postprocessed_source_code):
            symbol, value = token

            # Move the struct name to the STRUCT_DEF token
            if symbol == "STRUCT_DEF":
                struct_symbol, struct_name = postprocessed_source_code[idx + 1]

                try:
                    assert struct_symbol == "STRUCT"
                except AssertionError:
                    raise SyntaxError("Missing name in struct declaration.")
                
                new_token = (symbol, struct_name)
                postprocessed_source_code[idx] = new_token
                del postprocessed_source_code[idx + 1]

            # Correct the symbol for used defined variables
            elif symbol == "ID" and value in self.user_defined["structs"]:
                new_token = ("STRUCT_TYPE", value)
                postprocessed_source_code[idx] = new_token

            # Handle struct property access
            elif symbol == "ID" and "." in value:
                struct_var, struct_property = value.split(".")

                struct_var_token = (symbol, struct_var)
                dot_operation_token = (self.symbols.get("."), None)
                property_token = ("PROP", struct_property)

                postprocessed_source_code[idx] = struct_var_token
                postprocessed_source_code.insert(idx + 1, dot_operation_token)
                postprocessed_source_code.insert(idx + 2, property_token)

            # Handle array declaration/access
            elif symbol == "LBRA":

                # Array declaration
                try:
                    prev_symbol, _ = postprocessed_source_code[idx - 2]
                    is_declaration = "TYPE" in prev_symbol

                    # If declaring the array, change the associated integer symbol
                    # to ARRAY_SIZE
                    if is_declaration:
                        _, array_size = postprocessed_source_code[idx + 1]
                        array_manipulation_token = ("ARRAY_SIZE", array_size)

                    # If accessing an element in the array, change the symbol
                    # to ARRAY_INDEX
                    else:
                        _, array_index = postprocessed_source_code[idx + 1]
                        array_manipulation_token = ("ARRAY_INDEX", array_index)

                    postprocessed_source_code[idx + 1] = array_manipulation_token

                    # Also assert there is a RBRA after the integer
                    next_symbol, _ = postprocessed_source_code[idx + 2]
                    assert next_symbol == "RBRA"

                except (IndexError, AssertionError):
                    # If not either of previous cases, then the syntax is invalid :)
                    raise SyntaxError("Malformed array.")

        return postprocessed_source_code

    def validate_source_code_syntax(self, post_processed_source_code: list) -> None:
        """
        Validate the tokenized source code syntax.

        This method validates if variables and functions are typed, and if it
        doesn't use any reserved words as its names.

        Parameters
        ----------
        post_processed_source_code : list of (str, str | int | float | None) tuples
            The source code after being post-processed.

        Raises
        ------
        TODO
        """

        for idx, token in enumerate(post_processed_source_code):
            symbol, _ = token
            err_msg = ""

            # Check if there are variables or functions named after reserved words
            if "TYPE" in symbol:
                try:
                    next_symbol, _ = post_processed_source_code[idx + 1]

                    if next_symbol == "STRUCT_TYPE":
                        err_msg = "Variable named after user-defined struct."

                    if next_symbol in self.reserved_words.values():
                        err_msg = (
                            "Variable or function named after reserved word or"
                            + " symbol."
                        )

                except KeyError:
                    # If it raises a KeyError, then the current symbol is the
                    # last symbol of the tokenized source. Thus, it is invalid
                    err_msg = "Missing variable or function name after type."

            # Check if two variables appear in a row, without any operators
            # in between.
            if symbol == "ID":
                try:
                    next_symbol, _ = post_processed_source_code[idx + 1]

                    if next_symbol == "ID":
                        err_msg = (
                            "Multiple variables in a row without operator in"
                            + " between."
                        )

                except IndexError:
                    continue

            if err_msg:
                raise SyntaxError(err_msg)


def _extract_parameters(
    symbol_collection: list[str],
    function_idx: int
) -> list[tuple[str, str]]:
    """
    Extract the parameters from a function.

    The extracted parameters are returned as a list of (param_type, param_name)
    tuples.

    Parameters
    ----------
    symbol_collection : list of str
        The collection of symbols generated by the `split_source` method.
    function_idx : int
        The index of the function name in the `symbol_collection` list.

    Returns
    -------
    parameters : list of (param_type, param_name) tuples
        The list of function parameters. If the function take no parameters,
        return an empty list.
    """
    
    # Align with the index of the left parenthesis (add 1 to offset).
    curr_idx = function_idx + 1
    parameters = []

    try:
        while symbol_collection[curr_idx] != ")":
            curr_token = symbol_collection[curr_idx]

            if curr_token == "(":
                curr_idx += 1

            elif curr_token == ")":
                break

            else:
                param_type = curr_token
                param_name = symbol_collection[curr_idx + 1]

                if param_type not in Lexer.types:
                    function_name = symbol_collection[function_idx]
                    err_msg = (
                        f"Unknown type '{param_type}' in definition of "
                        + f"function '{function_name}'"
                    )
                    raise SyntaxError(err_msg)

                parameters.append((param_type, param_name))
                curr_idx += 2
    except IndexError:
        function_name = symbol_collection[function_idx]
        err_msg = f"Function '{function_name}' has malformed parameters."
        raise SyntaxError(err_msg)

    return parameters


def _get_function_limits(
    symbol_collection: list[str],
    function_idx: int
) -> tuple[int, int]:
    """
    Get the limits of the function in terms of indices.

    The function limits are refer to the index of the first and last tokens
    within the function scope in the `symbol_collection`.

    Parameters
    ----------
    symbol_collection : list of str
        The collection of symbols generated by the `split_source` method.
    function_idx : int
        The index of the function name in the `symbol_collection` list.

    Returns
    -------
    start : int
        The index, in the `symbol_collection`, of the first token within the
        function scope.
    end : int
        The index, in the `symbol_collection`, of the last token within the
        function scope.
    """

    brackets_stack = []
    function_begun = False
    start, end = (-1, -1)

    for relative_idx, token in enumerate(symbol_collection[function_idx:]):
        idx = relative_idx + function_idx

        if token == "{":
            start = idx + 1
            function_begun = True
            brackets_stack.append(1)

        elif token == "}":
            brackets_stack.pop()

        if not brackets_stack and function_begun:
            end = idx - 1
            break

    return (start, end)
